{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "from random import choice\n",
    "import string\n",
    "\n",
    "def prepare_simulation(seed, sample, n_simulations):\n",
    "    random_state = np.random.RandomState(seed)\n",
    "    simulation_matrix = random_state.choice(sample, size=n_simulations)\n",
    "    return simulation_matrix\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.12627422  0.96469566 -0.77522994 -0.76223404 -0.9925766 ]\n",
      " [-0.24958348 -0.86782805  1.89363683 -1.55530756  0.27694666]\n",
      " [ 0.15247171 -1.1773507   0.01342889 -0.96620304 -0.13391546]\n",
      " [ 0.48232482 -1.54693747 -0.18135229  1.41051844 -0.70507641]\n",
      " [-1.0909062  -0.03505605  0.16251799 -1.80723937  0.66648901]\n",
      " [ 1.12878487 -0.58353758  1.44818437  0.51148496  1.23070015]\n",
      " [ 1.2077587  -1.38653538  0.6653577   0.91239942  1.06451205]\n",
      " [-0.25550831 -0.49556759  2.99207254  1.45429851  0.43599191]\n",
      " [ 0.92323727 -0.28250646  0.15811125 -0.24718835  1.0097103 ]\n",
      " [ 0.56231774  1.77002369 -1.38774394  1.08059853 -1.62036334]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "norm_1 = norm(loc=0, scale=1)\n",
    "sample = np.sort(norm_1.rvs(10000))\n",
    "    \n",
    "n_trials = 10\n",
    "n_simulations = 5\n",
    "seeds = [int.from_bytes(bytearray(''.join(choice(string.ascii_lowercase) for _ in range(4)), encoding='utf-8'), 'big') for _ in range(n_trials)]\n",
    "simulation_matrix = np.array([prepare_simulation(seed, sample, n_simulations) for seed in seeds])\n",
    "print(simulation_matrix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.12627422,  0.96469566, -0.77522994, -0.76223404, -0.9925766 ],\n",
       "       [-0.24958348, -0.86782805,  1.89363683, -1.55530756,  0.27694666],\n",
       "       [ 0.15247171, -1.1773507 ,  0.01342889, -0.96620304, -0.13391546],\n",
       "       [ 0.48232482, -1.54693747, -0.18135229,  1.41051844, -0.70507641],\n",
       "       [-1.0909062 , -0.03505605,  0.16251799, -1.80723937,  0.66648901],\n",
       "       [ 1.12878487, -0.58353758,  1.44818437,  0.51148496,  1.23070015],\n",
       "       [ 1.2077587 , -1.38653538,  0.6653577 ,  0.91239942,  1.06451205],\n",
       "       [-0.25550831, -0.49556759,  2.99207254,  1.45429851,  0.43599191],\n",
       "       [ 0.92323727, -0.28250646,  0.15811125, -0.24718835,  1.0097103 ],\n",
       "       [ 0.56231774,  1.77002369, -1.38774394,  1.08059853, -1.62036334]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_session = SparkSession.builder.master('local[*]').getOrCreate()\n",
    "sc = spark_session.sparkContext\n",
    "\n",
    "simulation_matrix = sc.parallelize(seeds).flatMap(lambda x: prepare_simulation(x, sample, n_simulations))\n",
    "combined_simulation = np.array(simulation_matrix.collect()).reshape((n_trials, n_simulations))\n",
    "    \n",
    "spark_session.stop()\n",
    "\n",
    "combined_simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
